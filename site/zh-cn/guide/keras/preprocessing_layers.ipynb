{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b518b04cbfe0"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "906e07f6e562"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e083398b477"
      },
      "source": [
        "# Working with preprocessing layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64010bd23c2e"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>     <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/keras/preprocessing_layers\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">在 TensorFlow.org 上查看</a>   </td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/preprocessing_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">在 Google Colab 中运行 </a></td>\n",
        "  <td>     <a target=\"_blank\" href=\"https://github.com/keras-team/keras-io/blob/master/guides/preprocessing_layers.py\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a>   </td>\n",
        "  <td>     <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/keras/preprocessing_layers.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">下载笔记本</a>   </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5387d1418bf5"
      },
      "source": [
        "## Keras preprocessing layers\n",
        "\n",
        "The Keras preprocessing layers API allows developers to build Keras-native input\n",
        "processing pipelines. These input processing pipelines can be used as independent\n",
        "preprocessing code in non-Keras workflows, combined directly with Keras models, and\n",
        "exported as part of a Keras SavedModel.\n",
        "\n",
        "With Keras preprocessing layers, you can build and export models that are truly\n",
        "end-to-end: models that accept raw images or raw structured data as input; models that\n",
        "handle feature normalization or feature value indexing on their own."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0668a914b066"
      },
      "source": [
        "## 可用的预处理层\n",
        "\n",
        "### 核心预处理层\n",
        "\n",
        "- `TextVectorization` 层：将原始字符串转换为可以被 `Embedding` 层或 `Dense` 层读取的编码表示。\n",
        "- `Normalization` 层：对输入特征执行逐特征归一化。\n",
        "\n",
        "### 结构化数据预处理层\n",
        "\n",
        "这些层用于结构化数据编码和特征工程。\n",
        "\n",
        "- `CategoryEncoding` 层：将整数分类特征转换为独热、多热或计数密集表示。\n",
        "- `Hashing` 层：执行分类特征哈希（也称为“哈希技巧”）。\n",
        "- `Discretization` 层：将连续的数字特征转换为整数分类特征。\n",
        "- `StringLookup` 层：将字符串分类值转换为可以被 `Embedding` 层或 `Dense` 层读取的编码表示。\n",
        "- `IntegerLookup` 层：将整数分类值转换为可以被 `Embedding` 层或 `Dense` 层读取的编码表示。\n",
        "- `CategoryCrossing` 层：将分类特征组合成共现特征。例如，如果您有特征值“a”和“b”，它可以提供组合特征“a 和 b 同时存在”。\n",
        "\n",
        "### 图像预处理层\n",
        "\n",
        "这些层用于标准化图像模型的输入。\n",
        "\n",
        "- `Resizing` 层：将一批图像调整为目标大小。\n",
        "- `Rescaling` 层：重新缩放并偏移一批图像的值（例如，从 `[0, 255]` 范围内的输入到 `[0, 1]` 范围内的输入）。\n",
        "- `CenterCrop` 层：返回一批图像的中心裁剪。\n",
        "\n",
        "### 图像数据增强层\n",
        "\n",
        "这些层可对一批图像应用随机增强转换。它们仅在训练期间处于活动状态。\n",
        "\n",
        "- `RandomCrop` 层\n",
        "- `RandomFlip` 层\n",
        "- `RandomTranslation` 层\n",
        "- `RandomRotation` 层\n",
        "- `RandomZoom` 层\n",
        "- `RandomHeight` 层\n",
        "- `RandomWidth` 层"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2d9a4715fb2"
      },
      "source": [
        "## `adapt()` 方法\n",
        "\n",
        "某些预处理层具有必须根据训练数据的样本计算得出的内部状态。有状态预处理层的列表如下：\n",
        "\n",
        "- `TextVectorization`: 保留字符串标记与整数索引之间的映射\n",
        "- `StringLookup` 和 `IntegerLookup`：保留输入值与输出索引之间的映射。\n",
        "- `Normalization`：保留特征的平均值和标准差。\n",
        "- `Discretization`：保留有关值桶边界的信息。\n",
        "\n",
        "最关键的是，这些层**不可训练**。它们的状态并非在训练期间设置；必须在**训练之前**设置，此步骤称为“适配”。\n",
        "\n",
        "您可以通过 `adapt()` 方法将预处理层公开给训练数据，从而设置它的状态："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e05c8fc4d032"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "data = np.array([[0.1, 0.2, 0.3], [0.8, 0.9, 1.0], [1.5, 1.6, 1.7],])\n",
        "layer = preprocessing.Normalization()\n",
        "layer.adapt(data)\n",
        "normalized_data = layer(data)\n",
        "\n",
        "print(\"Features mean: %.2f\" % (normalized_data.numpy().mean()))\n",
        "print(\"Features std: %.2f\" % (normalized_data.numpy().std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d43b8246b8a3"
      },
      "source": [
        "`adapt()` 方法可以接受 Numpy 数组或 `tf.data.Dataset` 对象。对于 `StringLookup` 和 `TextVectorization`，您还可以传递字符串列表："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74ef94620592"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    \"ξεῖν᾽, ἦ τοι μὲν ὄνειροι ἀμήχανοι ἀκριτόμυθοι\",\n",
        "    \"γίγνοντ᾽, οὐδέ τι πάντα τελείεται ἀνθρώποισι.\",\n",
        "    \"δοιαὶ γάρ τε πύλαι ἀμενηνῶν εἰσὶν ὀνείρων:\",\n",
        "    \"αἱ μὲν γὰρ κεράεσσι τετεύχαται, αἱ δ᾽ ἐλέφαντι:\",\n",
        "    \"τῶν οἳ μέν κ᾽ ἔλθωσι διὰ πριστοῦ ἐλέφαντος,\",\n",
        "    \"οἵ ῥ᾽ ἐλεφαίρονται, ἔπε᾽ ἀκράαντα φέροντες:\",\n",
        "    \"οἱ δὲ διὰ ξεστῶν κεράων ἔλθωσι θύραζε,\",\n",
        "    \"οἵ ῥ᾽ ἔτυμα κραίνουσι, βροτῶν ὅτε κέν τις ἴδηται.\",\n",
        "]\n",
        "layer = preprocessing.TextVectorization()\n",
        "layer.adapt(data)\n",
        "vectorized_text = layer(data)\n",
        "print(vectorized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7619914dfb40"
      },
      "source": [
        "此外，可适配层总会公开一个选项，以直接通过构造函数参数或权重分配来设置状态。如果预期的状态值在构造层时已知，或在 `adapt()` 调用之外计算得出，则可以在不依赖层的内部计算的情况下进行设置。例如，如果 `TextVectorization`、`StringLookup` 或 `IntegerLookup` 层的外部词汇文件已经存在，则可以通过将词汇文件的路径传递到层的构造函数参数，直接将这些文件加载到查找表中。\n",
        "\n",
        "下面是一个示例，我们使用预计算的词汇实例化一个 `StringLookup` 层："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76aeb9346838"
      },
      "outputs": [],
      "source": [
        "vocab = [\"a\", \"b\", \"c\", \"d\"]\n",
        "data = tf.constant([[\"a\", \"c\", \"d\"], [\"d\", \"z\", \"b\"]])\n",
        "layer = preprocessing.StringLookup(vocabulary=vocab)\n",
        "vectorized_data = layer(data)\n",
        "print(vectorized_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cd07d2533da"
      },
      "source": [
        "## Preprocessing data before the model or inside the model\n",
        "\n",
        "There are two ways you could be using preprocessing layers:\n",
        "\n",
        "**Option 1:** Make them part of the model, like this:\n",
        "\n",
        "```python\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "x = preprocessing_layer(inputs)\n",
        "outputs = rest_of_the_model(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "```\n",
        "\n",
        "With this option, preprocessing will happen on device, synchronously with the rest of the\n",
        "model execution, meaning that it will benefit from GPU acceleration.\n",
        "If you're training on GPU, this is the best option for the `Normalization` layer, and for\n",
        "all image preprocessing and data augmentation layers.\n",
        "\n",
        "**Option 2:** apply it to your `tf.data.Dataset`, so as to obtain a dataset that yields\n",
        "batches of preprocessed data, like this:\n",
        "\n",
        "```python\n",
        "dataset = dataset.map(\n",
        "  lambda x, y: (preprocessing_layer(x), y))\n",
        "```\n",
        "\n",
        "With this option, your preprocessing will happen on CPU, asynchronously, and will be\n",
        "buffered before going into the model.\n",
        "\n",
        "This is the best option for `TextVectorization`, and all structured data preprocessing\n",
        "layers. It can also be a good option if you're training on CPU\n",
        "and you use image preprocessing layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32f6d2a104b7"
      },
      "source": [
        "## 推断时在模型内部进行预处理的好处\n",
        "\n",
        "即使您选择了选项 2，您之后也可能希望导出仅用于推断的端到端模型，该模型将包括预处理层。这样做的主要好处是**它使您的模型可移植**，并且**有助于降低[训练-应用偏差](https://developers.google.com/machine-learning/guides/rules-of-ml#training-serving_skew)**。\n",
        "\n",
        "当所有数据预处理都是模型的一部分时，其他人就可以加载和使用您的模型，而无需了解如何对每个特征进行编码和归一化。您的推断模型将能够处理原始图像或原始结构化数据，而不需要模型的用户了解详细信息（例如，用于文本的分词方案，用于分类特征的索引编制方案，图像像素值被归一化为 `[-1, +1]` 还是 `[0, 1]`，等等）。如果要将模型导出到另一个运行时（如 TensorFlow.js），此功能就会尤为强大，您无需在 JavaScript 中重新实现预处理流水线。\n",
        "\n",
        "如果您最初将预处理层放在了 `tf.data` 流水线中，则可以导出一个推断模型，将预处理打包。只需实例化一个将预处理层和训练模型链接起来的新模型：\n",
        "\n",
        "```python\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "x = preprocessing_layer(inputs)\n",
        "outputs = training_model(x)\n",
        "inference_model = keras.Model(inputs, outputs)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff9bad6ba7d5"
      },
      "source": [
        "## Quick recipes\n",
        "\n",
        "### Image data augmentation (on-device)\n",
        "\n",
        "Note that image data augmentation layers are only active during training (similarly to\n",
        "the `Dropout` layer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a621c2645ae6"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        preprocessing.RandomFlip(\"horizontal\"),\n",
        "        preprocessing.RandomRotation(0.1),\n",
        "        preprocessing.RandomZoom(0.1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Create a model that includes the augmentation stage\n",
        "input_shape = (32, 32, 3)\n",
        "classes = 10\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "# Augment images\n",
        "x = data_augmentation(inputs)\n",
        "# Rescale image values to [0, 1]\n",
        "x = preprocessing.Rescaling(1.0 / 255)(x)\n",
        "# Add the rest of the model\n",
        "outputs = keras.applications.ResNet50(\n",
        "    weights=None, input_shape=input_shape, classes=classes\n",
        ")(x)\n",
        "model = keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51d369f0310f"
      },
      "source": [
        "您可以在[从头开始进行图像分类](https://keras.io/examples/vision/image_classification_from_scratch/)示例中查看类似设置的实际运作情况。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a79a1c48b2b7"
      },
      "source": [
        "### Normalizing numerical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5a7c8f6270b"
      },
      "outputs": [],
      "source": [
        "# Load some data\n",
        "(x_train, y_train), _ = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.reshape((len(x_train), -1))\n",
        "input_shape = x_train.shape[1:]\n",
        "classes = 10\n",
        "\n",
        "# Create a Normalization layer and set its internal state using the training data\n",
        "normalizer = preprocessing.Normalization()\n",
        "normalizer.adapt(x_train)\n",
        "\n",
        "# Create a model that include the normalization layer\n",
        "inputs = keras.Input(shape=input_shape)\n",
        "x = normalizer(inputs)\n",
        "outputs = layers.Dense(classes, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Train the model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62685d477010"
      },
      "source": [
        "### Encoding string categorical features via one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79d7eb36272a"
      },
      "outputs": [],
      "source": [
        "# Define some toy data\n",
        "data = tf.constant([[\"a\"], [\"b\"], [\"c\"], [\"b\"], [\"c\"], [\"a\"]])\n",
        "\n",
        "# Use StringLookup to build an index of the feature values and encode output.\n",
        "lookup = preprocessing.StringLookup(output_mode=\"binary\")\n",
        "lookup.adapt(data)\n",
        "\n",
        "# Convert new test data (which includes unknown feature values)\n",
        "test_data = tf.constant([[\"a\"], [\"b\"], [\"c\"], [\"d\"], [\"e\"], [\"\"]])\n",
        "encoded_data = lookup(test_data)\n",
        "print(encoded_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "936cdacdea05"
      },
      "source": [
        "请注意，索引 0 保留用于缺失值（应将其指定为空字符串`\"\"`），索引 1 保留用于词汇外的值（未在 `adapt()` 期间看到的值）。您可以使用 `StringLookup` 的 `mask_token` 和 `oov_token` 构造函数参数进行配置。\n",
        "\n",
        "您可以在[从头开始进行结构化数据分类](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)示例中查看 `StringLookup` 的实际运作情况。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc8af3e290df"
      },
      "source": [
        "### Encoding integer categorical features via one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bbb10255083"
      },
      "outputs": [],
      "source": [
        "# Define some toy data\n",
        "data = tf.constant([[10], [20], [20], [10], [30], [0]])\n",
        "\n",
        "# Use IntegerLookup to build an index of the feature values and encode output.\n",
        "lookup = preprocessing.IntegerLookup(output_mode=\"binary\")\n",
        "lookup.adapt(data)\n",
        "\n",
        "# Convert new test data (which includes unknown feature values)\n",
        "test_data = tf.constant([[10], [10], [20], [50], [60], [0]])\n",
        "encoded_data = lookup(test_data)\n",
        "print(encoded_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da5a6be487be"
      },
      "source": [
        "请注意，索引 0 保留用于缺失值（应将其指定为值 0），索引 1 保留用于词汇外的值（未在 `adapt()` 期间看到的值）。您可以使用 `IntegerLookup` 的 `mask_token` 和 `oov_token` 构造函数参数进行配置。\n",
        "\n",
        "您可以在[从头开始进行结构化数据分类](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/)示例中查看 `IntegerLookup` 的实际运作情况。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fbfaa6ab3e2"
      },
      "source": [
        "### Applying the hashing trick to an integer categorical feature\n",
        "\n",
        "如果您有一个可以接受许多不同值（处于 10e3 或更高的数量级）的分类特征，其中每个值只在数据中出现几次，那么对特征值进行索引和独热编码将变得不切实际且没有效果。相反，应用“哈希技巧”可能会是个好主意：将值变换成固定大小的向量。这样可以使特征空间的大小易于管理，并且无需显式索引编制。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bd2f74332db"
      },
      "outputs": [],
      "source": [
        "# Sample data: 10,000 random integers with values between 0 and 100,000\n",
        "data = np.random.randint(0, 100000, size=(10000, 1))\n",
        "\n",
        "# Use the Hashing layer to hash the values to the range [0, 64]\n",
        "hasher = preprocessing.Hashing(num_bins=64, salt=1337)\n",
        "\n",
        "# Use the CategoryEncoding layer to one-hot encode the hashed values\n",
        "encoder = preprocessing.CategoryEncoding(num_tokens=64, output_mode=\"binary\")\n",
        "encoded_data = encoder(hasher(data))\n",
        "print(encoded_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df69b434d327"
      },
      "source": [
        "### Encoding text as a sequence of token indices\n",
        "\n",
        "这是您应该对要传递到 `Embedding` 层的文本进行预处理的方式。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a689d9dcf6ab"
      },
      "outputs": [],
      "source": [
        "# Define some text data to adapt the layer\n",
        "data = tf.constant(\n",
        "    [\n",
        "        \"The Brain is wider than the Sky\",\n",
        "        \"For put them side by side\",\n",
        "        \"The one the other will contain\",\n",
        "        \"With ease and You beside\",\n",
        "    ]\n",
        ")\n",
        "# Instantiate TextVectorization with \"int\" output_mode\n",
        "text_vectorizer = preprocessing.TextVectorization(output_mode=\"int\")\n",
        "# Index the vocabulary via `adapt()`\n",
        "text_vectorizer.adapt(data)\n",
        "\n",
        "# You can retrieve the vocabulary we indexed via get_vocabulary()\n",
        "vocab = text_vectorizer.get_vocabulary()\n",
        "print(\"Vocabulary:\", vocab)\n",
        "\n",
        "# Create an Embedding + LSTM model\n",
        "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = layers.Embedding(input_dim=len(vocab), output_dim=64)(x)\n",
        "outputs = layers.LSTM(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Call the model on test data (which includes unknown tokens)\n",
        "test_data = tf.constant([\"The Brain is deeper than the sea\"])\n",
        "test_output = model(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a84d4f2ec0ef"
      },
      "source": [
        "您可以在[从头进行文本分类](https://keras.io/examples/nlp/text_classification_from_scratch/)示例中查看 `TextVectorization` 层与 <code>Embedding</code> 模式组合的实际运作情况。\n",
        "\n",
        "请注意，在训练此类模型时，为了获得最佳性能，您应将 `TextVectorization` 层用作输入流水线的一部分（我们在上面的文本分类示例中就是这样做的）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28c2f2ff61fb"
      },
      "source": [
        "### Encoding text as a dense matrix of ngrams with multi-hot encoding\n",
        "\n",
        "这是您应该对要传递到 `Dense` 层的文本进行预处理的方式。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b62472e32529"
      },
      "outputs": [],
      "source": [
        "# Define some text data to adapt the layer\n",
        "data = tf.constant(\n",
        "    [\n",
        "        \"The Brain is wider than the Sky\",\n",
        "        \"For put them side by side\",\n",
        "        \"The one the other will contain\",\n",
        "        \"With ease and You beside\",\n",
        "    ]\n",
        ")\n",
        "# Instantiate TextVectorization with \"binary\" output_mode (multi-hot)\n",
        "# and ngrams=2 (index all bigrams)\n",
        "text_vectorizer = preprocessing.TextVectorization(output_mode=\"binary\", ngrams=2)\n",
        "# Index the bigrams via `adapt()`\n",
        "text_vectorizer.adapt(data)\n",
        "\n",
        "print(\n",
        "    \"Encoded text:\\n\",\n",
        "    text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\n",
        "    \"\\n\",\n",
        ")\n",
        "\n",
        "# Create a Dense model\n",
        "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Call the model on test data (which includes unknown tokens)\n",
        "test_data = tf.constant([\"The Brain is deeper than the sea\"])\n",
        "test_output = model(test_data)\n",
        "\n",
        "print(\"Model output:\", test_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "336a4d3426ed"
      },
      "source": [
        "### Encoding text as a dense matrix of ngrams with TF-IDF weighting\n",
        "\n",
        "This is an alternative way of preprocessing text before passing it to a `Dense` layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdf16938fe7c"
      },
      "outputs": [],
      "source": [
        "# Define some text data to adapt the layer\n",
        "data = tf.constant(\n",
        "    [\n",
        "        \"The Brain is wider than the Sky\",\n",
        "        \"For put them side by side\",\n",
        "        \"The one the other will contain\",\n",
        "        \"With ease and You beside\",\n",
        "    ]\n",
        ")\n",
        "# Instantiate TextVectorization with \"tf-idf\" output_mode\n",
        "# (multi-hot with TF-IDF weighting) and ngrams=2 (index all bigrams)\n",
        "text_vectorizer = preprocessing.TextVectorization(output_mode=\"tf-idf\", ngrams=2)\n",
        "# Index the bigrams and learn the TF-IDF weights via `adapt()`\n",
        "text_vectorizer.adapt(data)\n",
        "\n",
        "print(\n",
        "    \"Encoded text:\\n\",\n",
        "    text_vectorizer([\"The Brain is deeper than the sea\"]).numpy(),\n",
        "    \"\\n\",\n",
        ")\n",
        "\n",
        "# Create a Dense model\n",
        "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "outputs = layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Call the model on test data (which includes unknown tokens)\n",
        "test_data = tf.constant([\"The Brain is deeper than the sea\"])\n",
        "test_output = model(test_data)\n",
        "print(\"Model output:\", test_output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "preprocessing_layers.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
